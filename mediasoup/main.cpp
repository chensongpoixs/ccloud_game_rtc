/*
libboost_chrono-vc140-mt-gd-1_60.lib
libboost_date_time-vc140-mt-gd-1_60.lib
libboost_filesystem-vc140-mt-gd-1_60.lib
libboost_locale-vc140-mt-gd-1_60.lib
libboost_regex-vc140-mt-gd-1_60.lib
libboost_system-vc140-mt-gd-1_60.lib
libboost_thread-vc140-mt-gd-1_60.lib
libprotobuf-lited.lib
libprotobufd.lib
libprotocd.lib
..\libsdptransform\Debug\sdptransform.lib
obj/webrtc.lib
advapi32.lib
comdlg32.lib
dbghelp.lib
dnsapi.lib
gdi32.lib
msimg32.lib
odbc32.lib
odbccp32.lib
oleaut32.lib
shell32.lib
shlwapi.lib
user32.lib
usp10.lib
uuid.lib
version.lib
wininet.lib
winmm.lib
winspool.lib
ws2_32.lib
delayimp.lib
kernel32.lib
ole32.lib
crypt32.lib
iphlpapi.lib
secur32.lib
dmoguids.lib
wmcodecdspuuid.lib
amstrmid.lib
msdmo.lib
strmiids.lib
d3d11.lib
dxgi.lib
obj/api/create_peerconnection_factory.lib
obj/api/libjingle_peerconnection_api.lib
obj/media/rtc_media_base.lib
obj/p2p/rtc_p2p.lib
obj/api/audio_codecs/builtin_audio_decoder_factory.lib
obj/api/audio_codecs/builtin_audio_encoder_factory.lib
obj/api/video_codecs/builtin_video_decoder_factory.lib
obj/api/video_codecs/builtin_video_encoder_factory.lib
obj/media/rtc_audio_video.lib
obj/modules/audio_processing/audio_processing.lib
obj/modules/video_capture/video_capture_module.lib
obj/pc/peerconnection.lib
obj/rtc_base/rtc_base.lib
obj/rtc_base/experiments/field_trial_parser.lib
obj/api/transport/network_control.lib
obj/third_party/boringssl/boringssl.lib
obj/third_party/boringssl/boringssl_asm.lib
obj/logging/rtc_event_log_impl_base.lib
obj/logging/rtc_event_log_impl_encoder.lib
obj/modules/audio_coding/audio_network_adaptor_config.lib
obj/modules/remote_bitrate_estimator/remote_bitrate_estimator.lib
obj/common_video/common_video.lib
win_clang_x64/obj/third_party/libyuv/libyuv_internal.lib
obj/third_party/libjpeg_turbo/libjpeg.lib
obj/third_party/libjpeg_turbo/simd.lib
obj/third_party/libjpeg_turbo/simd_asm.lib
obj/system_wrappers/system_wrappers.lib
obj/rtc_base/rtc_numerics.lib
obj/logging/rtc_event_log2_proto.lib
obj/third_party/protobuf/protobuf_lite.lib
obj/logging/rtc_event_log_proto.lib
obj/modules/audio_coding/audio_network_adaptor.lib
obj/common_audio/common_audio.lib
obj/common_audio/common_audio_sse2.lib
obj/modules/audio_coding/ana_config_proto.lib
obj/modules/audio_coding/ana_debug_dump_proto.lib
obj/media/rtc_constants.lib
obj/modules/utility/utility.lib
obj/modules/audio_processing/config.lib
obj/modules/audio_processing/audio_buffer.lib
obj/audio/utility/audio_frame_operations.lib
obj/modules/audio_processing/aec3/aec3.lib
obj/modules/audio_processing/vad/vad.lib
obj/third_party/pffft/pffft.lib
obj/p2p/libstunprober.lib
obj/rtc_base/weak_ptr.lib
obj/api/video/builtin_video_bitrate_allocator_factory.lib
obj/modules/video_coding/encoded_frame.lib
obj/rtc_base/experiments/alr_experiment.lib
obj/rtc_base/experiments/rtt_mult_experiment.lib
obj/modules/rtp_rtcp/rtp_rtcp.lib
obj/rtc_base/experiments/quality_scaling_experiment.lib
obj/rtc_base/experiments/rate_control_settings.lib
obj/modules/video_coding/webrtc_vp9_helpers.lib
obj/api/video_codecs/rtc_software_fallback_wrappers.lib
obj/call/call.lib
obj/modules/bitrate_controller/bitrate_controller.lib
obj/modules/pacing/pacing.lib
obj/api/transport/goog_cc.lib
obj/modules/congestion_controller/goog_cc/goog_cc.lib
obj/modules/congestion_controller/congestion_controller.lib
obj/modules/congestion_controller/transport_feedback.lib
obj/modules/congestion_controller/rtp/transport_feedback.lib
obj/audio/audio.lib
obj/modules/audio_coding/audio_coding.lib
obj/modules/audio_coding/neteq.lib
obj/modules/audio_coding/webrtc_cng.lib
obj/modules/audio_coding/audio_encoder_cng.lib
obj/rtc_base/experiments/audio_allocation_settings.lib
obj/modules/video_coding/video_coding.lib
obj/modules/video_coding/packet.lib
obj/rtc_base/experiments/jitter_upper_bound_experiment.lib
obj/video/video.lib
obj/modules/video_coding/nack_module.lib
obj/modules/video_processing/video_processing.lib
obj/modules/video_processing/video_processing_sse2.lib
obj/rtc_base/experiments/keyframe_interval_settings_experiment.lib
obj/modules/audio_mixer/audio_mixer_impl.lib
obj/modules/audio_mixer/audio_frame_manipulator.lib
obj/pc/rtc_pc_base.lib
obj/media/rtc_data.lib
obj/third_party/usrsctp/usrsctp.lib
obj/third_party/libsrtp/libsrtp.lib
obj/rtc_base/experiments/normalize_simulcast_size_experiment.lib
obj/modules/audio_processing/audioproc_debug_proto.lib
obj/stats/rtc_stats.lib
obj/api/audio_codecs/L16/audio_decoder_L16.lib
obj/modules/audio_coding/pcm16b.lib
obj/modules/audio_coding/g711.lib
obj/modules/audio_coding/legacy_encoded_audio_frame.lib
obj/api/audio_codecs/g711/audio_decoder_g711.lib
obj/api/audio_codecs/g722/audio_decoder_g722.lib
obj/modules/audio_coding/g722.lib
obj/api/audio_codecs/isac/audio_decoder_isac_float.lib
obj/modules/audio_coding/isac.lib
obj/modules/audio_coding/isac_c.lib
obj/modules/audio_coding/isac_common.lib
obj/api/audio_codecs/ilbc/audio_decoder_ilbc.lib
obj/modules/audio_coding/ilbc.lib
obj/api/audio_codecs/opus/audio_decoder_multiopus.lib
obj/api/audio_codecs/opus/audio_encoder_opus_config.lib
obj/modules/audio_coding/webrtc_multiopus.lib
obj/third_party/opus/opus.lib
obj/modules/audio_coding/audio_coding_opus_common.lib
obj/api/audio_codecs/opus/audio_decoder_opus.lib
obj/modules/audio_coding/webrtc_opus.lib
obj/api/audio_codecs/L16/audio_encoder_L16.lib
obj/api/audio_codecs/g711/audio_encoder_g711.lib
obj/api/audio_codecs/g722/audio_encoder_g722.lib
obj/api/audio_codecs/isac/audio_encoder_isac_float.lib
obj/api/audio_codecs/ilbc/audio_encoder_ilbc.lib
obj/media/rtc_internal_video_codecs.lib
obj/media/rtc_encoder_simulcast_proxy.lib
obj/media/rtc_simulcast_encoder_adapter.lib
obj/modules/video_coding/webrtc_h264.lib
obj/modules/video_coding/webrtc_multiplex.lib
obj/modules/video_coding/webrtc_vp8.lib
obj/modules/video_coding/webrtc_vp8_temporal_layers.lib
obj/api/video_codecs/vp8_temporal_layers_factory.lib
obj/rtc_base/experiments/cpu_speed_experiment.lib
obj/third_party/libvpx/libvpx.lib
obj/third_party/libvpx/libvpx_yasm.lib
..\Debug\mediasoupclient.lib
*/
#include "Broadcaster.hpp"
#include "mediasoupclient.hpp"
//#include <cpr/cpr.h>
#include <csignal> // sigsuspend()
#include <cstdlib>
#include <iostream>
#include <string>
#include "httplib.h"
#include "cwebsocket_mgr.h"
#include "ccfg.h"
#include <WinUser.h>
#include <Windows.h>
#include "Broadcaster.hpp"
#include "cwebsocket_mgr.h"
#include "ccfg.h"
#include "httplib.h"
using json = nlohmann::json;
Broadcaster broadcaster;
bool stoped = false;
void signalHandler(int signum)
{
	RTC_LOG(LS_INFO) << "[INFO] interrupt signal (" << signum << ") received";

	webrtc::g_websocket_mgr.destroy();
	// Remove broadcaster from the server.
	broadcaster.Stop();
	RTC_LOG(LS_INFO) << "[INFO] leaving!" ;
	stoped = true;
	std::exit(signum);
}


void test_win()
{

	//SetWindowPos(nullptr, -1, 0, 0, 0, 0, 3);
	int width =  GetSystemMetrics(SM_CXVIRTUALSCREEN);//虚拟桌面宽度

	  width =  GetSystemMetrics(SM_CYVIRTUALSCREEN);//虚拟桌面高度

	  width =  GetSystemMetrics(SM_XVIRTUALSCREEN );//虚拟桌面左上角X坐标

	  width =  GetSystemMetrics(SM_YVIRTUALSCREEN );//虚拟桌面左上角Y坐标
	// 获取带标题栏和菜单栏即全屏像素大小
	  width = GetSystemMetrics(SM_CXSCREEN) ;
	int height = GetSystemMetrics(SM_CYSCREEN);


	printf("width = %d, height = %d\n", width, height);
	// 睡眠5s，准备时间
	//Sleep(5000);
	// 死循环
	int w = 1920;
	while (1) 
	{
		w += 32;
		if (width < w)
		{
		//	w = 0;
		}
		printf("-%d----\n", w);
		// 移动到绝对位置右击
		//mouse_event(MOUSEEVENTF_WHEEL, 0, 0, w, 0);
		mouse_event(MOUSEEVENTF_ABSOLUTE  | MOUSEEVENTF_LEFTDOWN | MOUSEEVENTF_LEFTUP/* | MOUSEEVENTF_RIGHTDOWN | MOUSEEVENTF_RIGHTUP*/ /*| MOUSEEVENTF_MOVE*/, (w * 65536) / width , 362 * 65535 / height, 0, 0 );
		std::this_thread::sleep_for(std::chrono::seconds(3));

		// 按下'q'键
		//keybd_event(81, 0, 0, 0);
		//keybd_event(81, 0, KEYEVENTF_KEYUP, 0);
		//Sleep(500);
		w += 40;
		if (width < w)
		{
			//w = 0;
		}
		// 移动到绝对位置右击
		printf("-%d----\n", w);
		//mouse_event(MOUSEEVENTF_WHEEL, 0, 0, w, 0);
		mouse_event(MOUSEEVENTF_ABSOLUTE  /*| MOUSEEVENTF_MOVE*/ | MOUSEEVENTF_LEFTDOWN | MOUSEEVENTF_LEFTUP/*| MOUSEEVENTF_RIGHTDOWN  | MOUSEEVENTF_RIGHTUP*/ , (w * 65536) / width  , 760 * 65535 / height, 0, 0 );
		
		std::this_thread::sleep_for(std::chrono::seconds(3));
		
	}

}


void test_scroll()
{
	//1.先获得桌面窗口
	//HWND windows = ::GetDesktopWindow();
	//SCROLLINFO scrollinfo;
	////SCROLLINFO info;
	////scrollinfo.nPos = 50;
	//scrollinfo.cbSize = sizeof(SCROLLINFO);
	//scrollinfo.fMask = SIF_ALL;
	//scrollinfo.nPos = 10;
	//bool ret = 	GetScrollInfo(windows, SB_VERT, &scrollinfo/*SIF_ALL*/);


	/*cbSize = sizeof (SCROLLINFO) ;
	fMask = SIF_RANGE | SIF_PAGE ;
	nMin = 0 ;
	nMax = NUMLINES - 1 ;
	nPage = cyClient / cyChar ;
	SetScrollInfo (hwnd, SB_VERT, &si, TRUE) ;*/
	/*switch (nSBCode)
	{
	case SB_LINERIGHT:*/
		//if (scrollinfo.nPos < scrollinfo.nMax)
	bool x = true;
	int delta = 0;
		while(true)
		{
			//scrollinfo.nPos += 10;
			//SetScrollInfo(SB_HORZ, 0, &scrollinfo, 0);
			////ScrollWindow(-10, 0);
			//printf("pos = %d ----\n", scrollinfo.nPos);
			//std::this_thread::sleep_for(std::chrono::seconds(3));
			delta = 10;
			mouse_event(MOUSEEVENTF_ABSOLUTE |/*MOUSEEVENTF_HWHEEL*/  MOUSEEVENTF_WHEEL , 0, 0, delta, 0);
			printf("delta = %d\n", delta);
			std::this_thread::sleep_for(std::chrono::seconds(3));
		}
		

		//break;
	//}
}





#include <vector>
#include <thread>
#include <future>
#include <numeric>
#include <iostream>
#include <chrono>

void accumulate(std::vector<int>::iterator first,
	std::vector<int>::iterator last,
	std::promise<int> accumulate_promise)
{
	int sum = std::accumulate(first, last, 0);
	accumulate_promise.set_value(sum);  // 提醒 future
}

void do_work(std::promise<void> barrier)
{
	std::this_thread::sleep_for(std::chrono::seconds(1));
	barrier.set_value();
}

int test_promise()
{
	// 演示用 promise<int> 在线程间传递结果。
	std::vector<int> numbers = { 1, 2, 3, 4, 5, 6 };
	std::promise<int> accumulate_promise;
	std::future<int> accumulate_future = accumulate_promise.get_future();
	std::thread work_thread(accumulate, numbers.begin(), numbers.end(),
		std::move(accumulate_promise));

	// future::get() 将等待直至该 future 拥有合法结果并取得它
	// 无需在 get() 前调用 wait()
	//accumulate_future.wait();  // 等待结果
	std::cout << "result=" << accumulate_future.get() << '\n';
	work_thread.join();  // wait for thread completion

						 // 演示用 promise<void> 在线程间对状态发信号
	std::promise<void> barrier;
	std::future<void> barrier_future = barrier.get_future();
	std::thread new_work_thread(do_work, std::move(barrier));
	barrier_future.wait();
	new_work_thread.join();
	return 0;
}


void get_display()
{
	//枚举所有屏幕 
	DISPLAY_DEVICE ddDisplay;
	ZeroMemory(&ddDisplay, sizeof(ddDisplay));
	ddDisplay.cb = sizeof(ddDisplay);
	DEVMODE dm;
	ZeroMemory(&dm, sizeof(dm));
	dm.dmSize = sizeof(dm);
	//获取屏幕数量
	int screenNUm = GetSystemMetrics(SM_CMONITORS);
	if (screenNUm < 2)
	{
		//L"未发现第二个屏幕，请检查投影是否正常分屏"
	}
	//因为屏幕不是连续的所以需要逐个遍历 具体应该遍历多个才合适我不请
	//期望专业人士给予指点 默认屏幕在0位 但是接入的屏幕不在1位
	for (char i = 0; i < screenNUm +10; i++)
	{
		//下一步活为了获得每个显示设备的名字
		int flag = EnumDisplayDevices(NULL, i, &ddDisplay, NULL);
		flag = flag&&EnumDisplaySettings(ddDisplay.DeviceName, ENUM_CURRENT_SETTINGS, &dm);
		if (!flag)
		{
			continue;
		}
		printf("screenNUm = %d, devicename = %s\n", screenNUm, ddDisplay.DeviceName);
		HDC desktopDc = GetDC(NULL);
		int DPI = GetDeviceCaps(desktopDc, LOGPIXELSX);
		DeleteDC(desktopDc);
		float Bili;//屏幕的放大比例 
		switch (DPI)
		{
		case 96:
			Bili = 1.0;
			break;
		case 120:
			Bili = 1.25;
			break;
		case 144:
			Bili = 1.50;
			break;
		case 192:
			Bili = 2.00;
			break;

		default:
			break;
		}
		////这里拿到了第二屏幕的尺寸信息
		//CRect Sc2Rect = CRect(dm.dmPosition.x*Bili,
		//	dm.dmPosition.y*Bili, 
		//	(dm.dmPosition.x + dm.dmPelsWidth)*Bili, 
		//	(dm.dmPosition.y + dm.dmPelsHeight)*Bili);
	}


}






struct ALLMONITORINFO 

{ 

	HMONITOR hMonitor; 

	RECT     rect; 

	bool     isPrimary; 

}; 

BOOL CALLBACK MonitorEnumProc(__in  HMONITOR hMonitor, __in  HDC hdcMonitor, __in  LPRECT lprcMonitor, __in  LPARAM dwData) 
{ 

	std::vector<ALLMONITORINFO>& infoArray = *reinterpret_cast<std::vector<ALLMONITORINFO>* >(dwData); 

	ALLMONITORINFO monitorInfo; 

	monitorInfo.hMonitor = hMonitor; 

	//下面这句代码已经获取到了屏幕的分辨率，不管你有多少个屏幕都可以获取到，但是该分辨率是受缩放影响的。 

	monitorInfo.rect = *lprcMonitor; 

	infoArray.push_back(monitorInfo); 



	//这里是另一种获取屏幕分辨率的办法。 

	MONITORINFO monInfo; 

	monInfo.cbSize = sizeof(MONITORINFO); 

	//这个方法也是会受缩放影响，shit. 

	BOOL isGet = GetMonitorInfo(hMonitor, &monInfo); 

	if (isGet == TRUE) { 

		printf("rect wdith:%d,rect height:%d.\n", monInfo.rcMonitor.right - monInfo.rcMonitor.left, monInfo.rcMonitor.bottom - monInfo.rcMonitor.top);; 

	} 



	return TRUE; 

} 



int maintest() { 

	std::vector<ALLMONITORINFO> mInfo; 

	mInfo.clear(); 

	//get number of monitors 

	mInfo.reserve(GetSystemMetrics(SM_CMONITORS)); 

	EnumDisplayMonitors(NULL, NULL, MonitorEnumProc, reinterpret_cast<LPARAM>(&mInfo)); 



	//通过枚举之后，显示器的信息就存储到了mInfo里了。 

	return 1; 

} 

#include <windows.h>
#include <process.h>
#include <Tlhelp32.h>
#include <winbase.h>
#include <string.h>


void wchar2strstring(std::string & szDst, WCHAR * wchart)
{
	wchar_t * wtext = wchart;
	DWORD dwNmu = WideCharToMultiByte(CP_OEMCP, NULL, wtext, -1, NULL, 0, NULL, FALSE);
	char * psTest;
	psTest = new char[dwNmu];
	WideCharToMultiByte(CP_OEMCP, NULL, wtext, -1, psTest, dwNmu, NULL, FALSE);
	szDst = psTest;
	delete[]psTest;
}
void killProcessByName(const char *filename)
{
	HANDLE hSnapShot = CreateToolhelp32Snapshot(TH32CS_SNAPALL, NULL);
	PROCESSENTRY32 pEntry;
	pEntry.dwSize = sizeof (pEntry);
	BOOL hRes = Process32First(hSnapShot, &pEntry);
	while (hRes)
	{
		std::string exefile;
		wchar2strstring(exefile, pEntry.szExeFile);
		printf("exe_name = %s\n", exefile.c_str());
		if (strcmp(exefile.c_str(), filename) == 0)
		{
			HANDLE hProcess = OpenProcess(PROCESS_TERMINATE, 0,
				(DWORD) pEntry.th32ProcessID);
			if (hProcess != NULL)
			{
				TerminateProcess(hProcess, 9);
				CloseHandle(hProcess);
			}
		}
		hRes = Process32Next(hSnapShot, &pEntry);
	}
	CloseHandle(hSnapShot);
}


void start_kill()
{
	//killProcessByName("peerconnection_desktop.exe");
	STARTUPINFO si = { sizeof(si) };
	//si.lpDesktop = (LPWSTR)"1234567890";
	si.dwFlags = STARTF_USESHOWWINDOW;
	si.wShowWindow = SW_SHOWMAXIMIZED;
	PROCESS_INFORMATION pi = { 0 };
	//// C:/Users/Public/Nwt/cache/recv/DESKTOP-QL/JJ202111121500/WindowsNoEditor/Prj_ChengDu.exe
	////TCHAR szApp[MAX_PATH] = { _T("D:/Work/cmedia_server/webrtc_google/libmediasoupclient/build/test/Debug/test_mediasoupclient.exe  D:/Work/cmedia_server/webrtc_google/libmediasoupclient/build/test/Debug/client.cfg") };
	////char * szApp = "C:/Users/Public/Nwt/cache/recv/DESKTOP-QL/JJ202111121500/WindowsNoEditor/Prj_ChengDu.exe";
	TCHAR  szApp[MAX_PATH] = { L"D:/Work/cmedia_server/webrtc_google/src/out/test_vs2017_debug/peerconnection_desktop.exe" };
	//TCHAR szCmdLine[MAX_PATH] = {
	//	L"C:\\Windows\\System32\\rundll32.exe"
	//	L" D:\\Test.dll,TestFunc" // 注意前面的空格
	//};//CREATE_NO_WINDOW
	if (::CreateProcess(NULL, szApp, NULL, NULL, FALSE, 0, NULL, NULL, &si, &pi))
	{
		CloseHandle(pi.hThread);
		CloseHandle(pi.hProcess);
	}


	std::this_thread::sleep_for(std::chrono::seconds(3));
	killProcessByName("peerconnection_desktop.exe");
}
//int main()
//{
//	killProcessByName("notepad++.exe");
//	return 0;
//}
#include <Windows.h>
int main(int argc, char* argv[])
{
	//while (1);
	
	signal(SIGINT, signalHandler);
	const char* config_filename = "client.cfg";
	if (argc > 1)
	{
		config_filename = argv[1];
	}
	bool init = webrtc::g_cfg.init(config_filename);
	if (!init)
	{
		RTC_LOG(LS_ERROR) << "config init failed !!!" << config_filename;
		return -1;
	}
	webrtc::g_cfg.show();
	webrtc::g_cfg.show();
	std::string ws_url = "ws://" + webrtc::g_cfg.get_string(webrtc::ECI_MediaSoup_Host)+ ":" + std::to_string(webrtc::g_cfg.get_int32(webrtc::ECI_MediaSoup_Http_Port)) +"/?roomId="+webrtc::g_cfg.get_string(webrtc::ECI_Room_Name) +"&peerId=" + webrtc::g_cfg.get_string(webrtc::ECI_Client_Name);//ws://127.0.0.1:8888/?roomId=chensong&peerId=xiqhlyrn", "http://127.0.0.1:8888")
	std::string origin = "http://" + webrtc::g_cfg.get_string(webrtc::ECI_MediaSoup_Host)+ ":" + std::to_string(webrtc::g_cfg.get_int32(webrtc::ECI_MediaSoup_Http_Port)) ;
	if (!webrtc::g_websocket_mgr.init(ws_url, origin))
	{
		RTC_LOG(LS_ERROR) << "weboscket connect failed !!! url = " << ws_url;
		return -1;
	}
	webrtc::g_websocket_mgr.start();
	uint64_t id = 34;
	bool send = false;
	
	//while (true)
	//{
	//	//RTC_LOG(LS_INFO) << "websocket connect .... 100 ";
	//	/*{
	//	request : true,
	//		id      : 12345678,
	//		method  : 'chatmessage',
	//		data    :
	//	{
	//	type  : 'text',
	//		value : 'Hi there!'
	//	}
	//	}*/

	//	json body_data =
	//	{
	//		{
	//			
	//		}
	//			
	//	};
	//	json body =
	//	{
	//		{"request", true},
	//	{"id",++id}, //  
	//	{"method","getRouterRtpCapabilities"}, //方法
	//	{
	//		"data", {}
	//	}
	//	};
	//	RTC_LOG(LS_INFO) << body.dump().c_str();
	//	//if (!send)
	//	{
	//		webrtc::g_websocket_mgr.send(body.dump().c_str());
	//		send = true;
	//	}
	//	
	//	std::this_thread::sleep_for(std::chrono::seconds(10));
	//}
	//std::this_thread::sleep_for(std::chrono::seconds(10));


	mediasoupclient::Initialize();

	// Retrieve configuration from environment variables.
	//const char* envServerUrl    = std::getenv("SERVER_URL");
	//const char* envRoomId       = std::getenv("ROOM_ID");
	//const char* envEnableAudio  = std::getenv("ENABLE_AUDIO");
	//const char* envUseSimulcast = std::getenv("USE_SIMULCAST");
	const char* envWebrtcDebug  = std::getenv("WEBRTC_DEBUG");
	const char* envVerifySsl    = std::getenv("VERIFY_SSL");
	const char * envServerUrl = origin.c_str();
	std::string room_name =  webrtc::g_cfg.get_string(webrtc::ECI_Room_Name);
	const char * envRoomId = room_name.c_str();
	const char * envEnableAudio = "false";
	std::string client_name = webrtc::g_cfg.get_string(webrtc::ECI_Client_Name);
	const char * name =  client_name.c_str();
	const char* envUseSimulcast = "false";
	if (envServerUrl == nullptr)
	{
		std::cerr << "[ERROR] missing 'SERVER_URL' environment variable" << std::endl;

		return 1;
	}

	if (envRoomId == nullptr)
	{
		std::cerr << "[ERROR] missing 'ROOM_ID' environment variable" << std::endl;

		return 1;
	}

	std::string baseUrl = envServerUrl;
	baseUrl.append("/rooms/").append(envRoomId);

	bool enableAudio = true;

	if (envEnableAudio && std::string(envEnableAudio) == "false")
		enableAudio = false;

	bool useSimulcast = true;

	if (envUseSimulcast && std::string(envUseSimulcast) == "false")
		useSimulcast = false;

	bool verifySsl = true;
	if (envVerifySsl && std::string(envVerifySsl) == "false")
		verifySsl = false;

	// Set RTC logging severity.
	if (envWebrtcDebug)
	{
		if (std::string(envWebrtcDebug) == "info")
			rtc::LogMessage::LogToDebug(rtc::LoggingSeverity::LS_INFO);
		else if (std::string(envWebrtcDebug) == "warn")
			rtc::LogMessage::LogToDebug(rtc::LoggingSeverity::LS_WARNING);
		else if (std::string(envWebrtcDebug) == "error")
			rtc::LogMessage::LogToDebug(rtc::LoggingSeverity::LS_ERROR);
	}

	auto logLevel = mediasoupclient::Logger::LogLevel::LOG_DEBUG;
	mediasoupclient::Logger::SetLogLevel(logLevel);
	mediasoupclient::Logger::SetDefaultHandler();

	// Initilize mediasoupclient.
	mediasoupclient::Initialize();

	std::cout << "[INFO] welcome to mediasoup broadcaster app!\n" << std::endl;

	std::cout << "[INFO] verifying that room '" << envRoomId << "' exists..." << std::endl;
	/*auto r = cpr::GetAsync(cpr::Url{ baseUrl }, cpr::VerifySsl{ verifySsl }).get();

	if (r.status_code != 200)
	{
		std::cerr << "[ERROR] unable to retrieve room info"
		          << " [status code:" << r.status_code << ", body:\"" << r.text << "\"]" << std::endl;

		return 1;
	}
	else
	{
		std::cout << "[INFO] found room" << envRoomId << std::endl;
	}*/
	std::string host =webrtc::g_cfg.get_string(webrtc::ECI_MediaSoup_Host) ;
	httplib::Client cli(host, webrtc::g_cfg.get_uint32(webrtc::ECI_MediaSoup_Http_Port));
	std::string url = baseUrl;
	auto res = cli.Get(url.c_str());
	if (!res)
	{
		RTC_LOG(LS_ERROR) << "[ERROR]Stop";

		//	promise.set_exception(std::make_exception_ptr(res->body));
		return -1;// promise.get_future();
	}
	if (res->status != 200)
	{
		RTC_LOG(LS_ERROR)  << "[ERROR] Stop"
			<< " [status code:" << res->status << ", body:\"" << res->body << "\"]" ;

		//promise.set_exception(std::make_exception_ptr(res->body));
		return -1;// promise.get_future();
	}

	RTC_LOG(INFO)  << __FUNCTION__ << __LINE__ <<"[" << res->body << "]" ;
	auto response = nlohmann::json::parse(res->body);

	

	broadcaster.Start(baseUrl, enableAudio, useSimulcast, response, verifySsl, name);

	std::cout << "[INFO] press Ctrl+C or Cmd+C to leave..." << std::endl;
	std::string new_url  =  url + "/chensong";
	std::set<std::string> dataProduceIds;
	while (!stoped)
	{
		//broadcaster.createDataConsumer();

		
		res = cli.Get(new_url.c_str());
		if (!res)
		{
			RTC_LOG(LS_ERROR) << "[ERROR]Stop";

			//	promise.set_exception(std::make_exception_ptr(res->body));
			//return -1;// promise.get_future();
		}
		if (res->status != 200)
		{
			RTC_LOG(LS_ERROR)  << "[ERROR] Stop"
				<< " [status code:" << res->status << ", body:\"" << res->body << "\"]" ;

			//promise.set_exception(std::make_exception_ptr(res->body));
			//return -1;// promise.get_future();
		}
		else
		{
			//RTC_LOG(INFO)  << __FUNCTION__ << __LINE__ <<"[" << res->body << "]" ;
			auto response = nlohmann::json::parse(res->body);

			if (response["peers"].is_array())
			{
				for (int i = 0; i < response["peers"].size(); ++i)
				{
					if (response["peers"][i]["displayName"] != "test" )
					{
						auto iter = dataProduceIds.find(response["peers"][i]["displayName"]);
						if (iter != dataProduceIds.end())
						{
							continue;
						}
						std::string displayName = response["peers"][i]["displayName"];
						
						for (int j = 0; j < response["peers"][i]["dataProducers"].size(); ++j)
						{
							if ("chat" == response["peers"][i]["dataProducers"][j]["label"])
							{
								//dataProduceIds;
								//std::string id = response["peers"][i]["dataProducers"][j]["id"];
								std::string dataProducerId = response["peers"][i]["dataProducers"][j]["id"];
								//uint32_t streamId = response["peers"][i]["dataConsumers"][j]["sctpStreamParameters"]["streamId"];
								//json AppData = response["peers"][i]["dataConsumers"][j]["sctpStreamParameters"]["AppData"];;
								json body =
								{
									{ "dataProducerId", dataProducerId }
								};
								broadcaster.CreateDataConsumer(body);
								RTC_LOG(LS_INFO) << "id = " << id << ", dataProducerId = " << dataProducerId;
								dataProduceIds.insert(displayName);
							}
						}
					}
				}
			}
		}
		

		std::this_thread::sleep_for(std::chrono::seconds(1));
		//std::cin.get();
	}

	return 0;
}
